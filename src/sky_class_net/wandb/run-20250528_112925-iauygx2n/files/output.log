ðŸŒ± Setting the seed to 0 for generating dataloaders.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type        | Params | Mode
----------------------------------------------
0 | model | SkyClassNet | 195    | train
----------------------------------------------
195       Trainable params
0         Non-trainable params
195       Total params
0.001     Total estimated model params size (MB)
8         Modules in train mode
0         Modules in eval mode
Sanity Checking DataLoader 0:   0%|                                                                                                                                                                                         | 0/2 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\arnau\work\lipid_internship\git\src\sky_class_net\sky_class_train.py", line 92, in <module>
    main()
  File "C:\Users\arnau\work\lipid_internship\git\src\sky_class_net\sky_class_train.py", line 85, in main
    trainer.fit(
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\trainer\trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\trainer\call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\trainer\trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1012, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1054, in _run_stage
    self._run_sanity_check()
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\trainer\trainer.py", line 1083, in _run_sanity_check
    val_loop.run()
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\loops\utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\loops\evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\loops\evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\trainer\call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\work\lipid_internship\git\.conda\Lib\site-packages\lightning\pytorch\strategies\strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\work\lipid_internship\git\src\lightning_models\sky_class_lightning_model.py", line 132, in validation_step
    return self._shared_step(batch, "val")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\work\lipid_internship\git\src\lightning_models\sky_class_lightning_model.py", line 79, in _shared_step
    _, sky_class, _, _, _, x = batch
    ^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: not enough values to unpack (expected 6, got 2)
