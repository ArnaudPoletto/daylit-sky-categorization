{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeaa63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.models.unet import UNet\n",
    "from src.lightning_models.unet_lightning_model import UNetLightningModel\n",
    "from src.datasets.sky_cover_dataset import SkyCoverModule\n",
    "from src.utils.file import get_paths_recursive\n",
    "from src.datasets.sky_finder import (\n",
    "    get_sky_finder_masks,\n",
    "    get_sky_finder_bounding_boxes,\n",
    "    get_sky_finder_paths_dict,\n",
    ")\n",
    "from src.config import (\n",
    "    DEVICE,\n",
    "    UNET_CHECKPOINT_PATH,\n",
    "    SKY_COVER_WIDTH,\n",
    "    SKY_COVER_HEIGHT,\n",
    "    SKY_FINDER_IMAGES_PATH,\n",
    "    SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model\n",
    "def get_model():\n",
    "    model = UNet(pretrained=True)\n",
    "    lightning_model = UNetLightningModel.load_from_checkpoint(\n",
    "        UNET_CHECKPOINT_PATH,\n",
    "        model=model,\n",
    "        learning_rate=0,\n",
    "        weight_decay=0,\n",
    "        name=\"unet\",\n",
    "        dataset=\"sky_finder\",\n",
    "    )\n",
    "    model = lightning_model.model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a315b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(\n",
    "    image_file_path: str,\n",
    "    mask: np.ndarray,\n",
    "    bounding_box: Tuple[int, int, int, int],\n",
    "    mean: np.ndarray = np.array([0.485, 0.456, 0.406], dtype=np.float32),\n",
    "    std: np.ndarray = np.array([0.229, 0.224, 0.225], dtype=np.float32),\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get image from file path.\n",
    "\n",
    "    Args:\n",
    "        image_file_path (str): Path to the image file.\n",
    "        mask (np.ndarray): Mask for the image.\n",
    "        bounding_box (Tuple[int, int, int, int]): Bounding box for cropping the image.\n",
    "        mean (np.ndarray, optional): Mean for normalization. Defaults to [0.485, 0.456, 0.406].\n",
    "        std (np.ndarray, optional): Standard deviation for normalization. Defaults to [0.229, 0.224, 0.225].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image as a numpy array.\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    image = cv2.imread(image_file_path, cv2.IMREAD_COLOR)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"❌ Failed to read image: {image_file_path}\")\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Crop image and mask based on bounding box\n",
    "    x_min, y_min, x_max, y_max = bounding_box\n",
    "    image = image[y_min:y_max, x_min:x_max]\n",
    "    mask = mask[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Apply inpainting to fill the ground\n",
    "    inpaint_mask = (~mask).astype(np.uint8) * 255\n",
    "    image = cv2.inpaint(image, inpaint_mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Resize and normalize image\n",
    "    image = cv2.resize(image, (SKY_COVER_WIDTH, SKY_COVER_HEIGHT))\n",
    "    image = image / 255.0\n",
    "    image = (image - mean) / std\n",
    "\n",
    "    return image\n",
    "\n",
    "def unnormalize_image(\n",
    "    image: np.ndarray,\n",
    "    mean: np.ndarray = np.array([0.485, 0.456, 0.406], dtype=np.float32),\n",
    "    std: np.ndarray = np.array([0.229, 0.224, 0.225], dtype=np.float32),\n",
    ") -> np.ndarray:\n",
    "    image = image * std + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c435dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model\n",
    "model = get_model()\n",
    "\n",
    "# Get image file paths\n",
    "image_file_paths = get_paths_recursive(\n",
    "    folder_path=SKY_FINDER_IMAGES_PATH,\n",
    "    match_pattern=\"*.jpg\",\n",
    "    path_type=\"f\",\n",
    "    recursive=True,\n",
    ")\n",
    "random.shuffle(image_file_paths)\n",
    "print(f\"✅ Found {len(image_file_paths)} images.\")\n",
    "\n",
    "paths_dict = get_sky_finder_paths_dict()\n",
    "masks = get_sky_finder_masks(paths_dict)\n",
    "bounding_boxes = get_sky_finder_bounding_boxes(paths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cbdd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "for image_file_path in tqdm(\n",
    "    image_file_paths, desc=\"⌛ Generating embeddings...\", unit=\"file\"\n",
    "):\n",
    "    sky_type = image_file_path.split(\"/\")[-3]\n",
    "    camera_id = image_file_path.split(\"/\")[-2]\n",
    "\n",
    "    if camera_id not in masks:\n",
    "        print(f\"❌ Camera ID {camera_id} not found in masks.\")\n",
    "        continue\n",
    "    mask = masks[camera_id]\n",
    "\n",
    "    if camera_id not in bounding_boxes:\n",
    "        print(f\"❌ Camera ID {camera_id} not found in bounding boxes.\")\n",
    "        continue\n",
    "    bounding_box = bounding_boxes[camera_id]\n",
    "\n",
    "    image = get_image(\n",
    "        image_file_path=image_file_path, mask=mask, bounding_box=bounding_box\n",
    "    )\n",
    "\n",
    "    input_image = torch.from_numpy(image).unsqueeze(0).permute(0, 3, 1, 2).float().to(DEVICE)\n",
    "    print(input_image.shape)\n",
    "    prediction = model(input_image).squeeze().cpu().detach().numpy()\n",
    "    prediction = np.clip(prediction, 0, 1)\n",
    "    prediction = (prediction * 255).astype(np.uint8)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(unnormalize_image(image))\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(prediction, cmap=\"gray\")\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81acfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
